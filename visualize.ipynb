{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from data_augmentation import MRIAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"E:\\Data\\ADNI\\adni-fnirt-corrected\\brain_adni_0021_I338266_fsld.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 91, 109, 91])\n",
      "(100, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# 使用nibabel加载nii.gz文件\n",
    "nii_img = nib.load(file_path)\n",
    "nii_img_process = nii_img.get_fdata()\n",
    "nii_img_process = nii_img_process.astype(np.float32)\n",
    "nii_img_process = torch.from_numpy(nii_img_process)\n",
    "nii_img_process = nii_img_process.unsqueeze(0)\n",
    "nii_img_numpy = nii_img_process\n",
    "print(nii_img_process.shape)\n",
    "\n",
    "data_transforms_resize = MRIAugmentation.get_pre_transforms()\n",
    "\n",
    "data_transforms = MRIAugmentation.get_augmentation_transforms()\n",
    "\n",
    "nii_img_resize = data_transforms_resize(nii_img_process).squeeze(0).numpy()\n",
    "nii_img_process = data_transforms(nii_img_process).squeeze(0).numpy()\n",
    "\n",
    "print(nii_img_process.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 100, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mri_dataset import ADNIDataset\n",
    "dataset = ADNIDataset(data_dir=\"E:/Data/ADNI/adni-fnirt-corrected\", csv_path=r\"E:\\Data\\ADNI\\single_subject.csv\", transform=MRIAugmentation.get_augmentation_transforms())\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 91, 109, 91])\n",
      "torch.Size([1, 100, 100, 100])\n",
      "metatensor([-0.5511, -0.5508, -0.5504, -0.5501, -0.5500, -0.5504, -0.5509, -0.5512,\n",
      "        -0.5510, -0.5506, -0.5508, -0.5509, -0.5504, -0.5504, -0.4735, -0.1624,\n",
      "         0.7002,  1.5896,  2.0779,  2.4024,  2.4890,  2.4772,  2.4757,  2.4614,\n",
      "         2.4467,  2.4166,  2.4110,  2.2447,  1.3265,  0.6702,  0.9850,  1.4433,\n",
      "         1.8677,  2.0772,  2.2055,  2.2857,  1.9784,  1.3905,  0.9271,  0.9086,\n",
      "         1.1382,  1.3871,  1.5799,  1.6350,  1.6331,  1.5902,  1.4097,  1.0965,\n",
      "         1.2292,  1.7531,  1.8126,  1.4981,  1.9957,  2.1640,  1.5191,  1.3617,\n",
      "         1.5677,  1.7592,  1.6752,  1.5986,  1.5217,  1.4775,  1.4051,  1.1233,\n",
      "         0.8571,  0.9117,  1.0486,  1.2107,  1.5880,  1.6412,  1.3759,  1.2279,\n",
      "         1.1658,  1.1454,  1.1293,  1.1248,  1.0659,  0.9984,  0.8003,  0.4036,\n",
      "         0.0876, -0.2770, -0.5372, -0.5505, -0.5505, -0.5498, -0.5495, -0.5499,\n",
      "        -0.5501, -0.5503, -0.5503, -0.5504, -0.5507, -0.5500, -0.5497, -0.5505,\n",
      "        -0.5503, -0.5503, -0.5509, -0.5510])\n",
      "metatensor([-0.5505, -0.5505, -0.5505, -0.5505, -0.5505, -0.5505, -0.5505, -0.5505,\n",
      "        -0.5505, -0.5505, -0.5505, -0.5505, -0.5505, -0.5505, -0.4738, -0.1626,\n",
      "         0.7002,  1.5895,  2.0777,  2.4022,  2.4892,  2.4774,  2.4759,  2.4612,\n",
      "         2.4464,  2.4169,  2.4110,  2.2444,  1.3270,  0.6707,  0.9849,  1.4435,\n",
      "         1.8683,  2.0777,  2.2060,  2.2857,  1.9774,  1.3904,  0.9273,  0.9082,\n",
      "         1.1382,  1.3875,  1.5807,  1.6353,  1.6323,  1.5895,  1.4096,  1.0969,\n",
      "         1.2297,  1.7533,  1.8123,  1.4981,  1.9966,  2.1647,  1.5187,  1.3609,\n",
      "         1.5674,  1.7592,  1.6751,  1.5984,  1.5217,  1.4775,  1.4052,  1.1235,\n",
      "         0.8565,  0.9111,  1.0483,  1.2105,  1.5881,  1.6412,  1.3757,  1.2282,\n",
      "         1.1663,  1.1456,  1.1294,  1.1250,  1.0660,  0.9981,  0.8005,  0.4038,\n",
      "         0.0867, -0.2776, -0.5372, -0.5505, -0.5505, -0.5505, -0.5505, -0.5505,\n",
      "        -0.5505, -0.5505, -0.5505, -0.5505, -0.5505, -0.5505, -0.5505, -0.5505,\n",
      "        -0.5505, -0.5505, -0.5505, -0.5505])\n"
     ]
    }
   ],
   "source": [
    "print(nii_img_numpy.shape)\n",
    "print(data_transforms(nii_img_numpy).shape)\n",
    "print(data_transforms(nii_img_numpy)[0][50][50])\n",
    "print(data_transforms(nii_img_numpy)[0][50][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nii_img_process[40][40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image为numpy数组\n",
    "def visualize(image, is_save = False, is_information = False, nii_img=None):\n",
    "\n",
    "    # 打印图像维度\n",
    "    print(\"Image shape:\", image.shape)\n",
    "\n",
    "    # 可视化每一层切片\n",
    "    num_slices = image.shape[-1]\n",
    "\n",
    "    # 设置子图的行数和列数\n",
    "    num_rows = num_slices // 10 + 1  # 每行显示10个切片\n",
    "    num_cols = min(num_slices, 10)\n",
    "\n",
    "    # 设置子图的大小\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
    "\n",
    "    # 遍历每一层切片并可视化\n",
    "    for i in range(num_slices):\n",
    "        row_idx = i // 10\n",
    "        col_idx = i % 10\n",
    "\n",
    "        # 在子图中显示每一层切片\n",
    "        axes[row_idx, col_idx].imshow(np.flipud(image[:,:,i].T), cmap='gray', vmin=0, vmax=1)\n",
    "        axes[row_idx, col_idx].axis('off')  # 关闭坐标轴\n",
    "\n",
    "    # 如果切片数量不是10的倍数，隐藏多余的子图\n",
    "    for i in range(num_slices, num_rows * num_cols):\n",
    "        row_idx = i // 10\n",
    "        col_idx = i % 10\n",
    "        fig.delaxes(axes[row_idx, col_idx])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # 保存切片\n",
    "    if is_save:\n",
    "        print(f\"num of slices:{num_slices}\")\n",
    "        plt.clf()\n",
    "        for i in range(num_slices):\n",
    "            # plt.imshow(image[:, :, i])\n",
    "            plt.imsave(f\"./image/slice_{i+1}.jpg\", image[:, :, i], cmap='gray', vmin=0, vmax=1)\n",
    "            \n",
    "\n",
    "\n",
    "    if is_information:\n",
    "    # 查看图像大小\n",
    "        height, width, depth = image.shape\n",
    "        print(f\"The image object height: {height}, width:{width}, depth:{depth}\")\n",
    "        # 查看图像值范围\n",
    "        print(f'image value range: [{image.min()}, {image.max()}]')\n",
    "\n",
    "        # 查看图像成像信息，如 层厚，平面（in-plane）分辨率等\n",
    "\n",
    "        # 矩阵以外的信息可以通过 image_obj.header 获取\n",
    "\n",
    "        # header是键值对，查看 header 包含的所有信息\n",
    "        print('headers', nii_img.header.keys())\n",
    "        # 查看成像信息\n",
    "        pixdim = nii_img.header['pixdim']\n",
    "        print(f'z轴分辨率： {pixdim[3]}')\n",
    "        print(f'in plane 分辨率： {pixdim[1]} * {pixdim[2]}')\n",
    "        x_range = pixdim[1] * height\n",
    "        y_range = pixdim[2] * width\n",
    "        z_range = pixdim[3] * depth\n",
    "        print(f\"The image object x_range: {x_range}, y_range:{y_range}, z_range:{z_range}\")\n",
    "        # 整个数据\n",
    "        print('img1_obj', nii_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image_0_to_1(image):\n",
    "    \"\"\"\n",
    "    将输入的三维图像归一化到0-1范围。\n",
    "    :param image: 三维Numpy数组，代表图像数据。\n",
    "    :return: 归一化后的图像数据。\n",
    "    \"\"\"\n",
    "    # 计算图像的最小值和最大值\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    \n",
    "    # 应用最大-最小归一化\n",
    "    normalized_image = (image - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(normalize_image_0_to_1(nii_img.get_fdata()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(normalize_image_0_to_1(nii_img_resize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img_process_normailized = normalize_image_0_to_1(nii_img_process)\n",
    "visualize(nii_img_process_normailized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img_process_normailized[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
