{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mri_dataset import ADNIDataset\n",
    "from monai.transforms import *\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size=256):\n",
    "    dataset_dir = r\"E:\\Data\\ADNI\\adni-fnirt-corrected\"\n",
    "    csv_path = r\"E:\\Data\\ADNI\\single_subject.csv\"\n",
    "    size = 100\n",
    "    data_transforms = Compose([\n",
    "        # RandRotate90(prob=0.5, spatial_axes=[1, 2]),\n",
    "        # RandFlip(prob=0.5, spatial_axis=0),\n",
    "        \n",
    "        # RandAdjustContrast(prob=0.5),\n",
    "        # RandGaussianNoise(prob=0.3),\n",
    "        # RandAffine(prob=0.5, translate_range=10, scale_range=(0.9, 1.1), rotate_range=45),\n",
    "        \n",
    "        Resize(spatial_size=[size, size, size]),\n",
    "        NormalizeIntensity(nonzero=True, channel_wise=True),\n",
    "    ])\n",
    "    dataset = ADNIDataset(data_dir=dataset_dir, csv_path=csv_path, transform=data_transforms)\n",
    "    dataset_size = len(dataset)\n",
    "    train_size = int(dataset_size * 0.7)\n",
    "    test_size = dataset_size - train_size\n",
    "    print('dataset_size:', dataset_size)\n",
    "    print('train_size:', train_size)\n",
    "    print('test_size:', test_size)\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'vgg', 'batch_size': 8, 'csv_path': 'E:\\\\Data\\\\ADNI\\\\pheno_ADNI_longitudinal_new.csv', 'dataset_dir': 'E:\\\\Data\\\\ADNI\\\\adni-fnirt-corrected', 'dataset_name': 'mri', 'device': 'cuda', 'disable_cuda': False, 'epochs': 150, 'fp16_precision': False, 'learning_rate': 1e-05, 'log_every_n_steps': 100, 'n_views': 2, 'out_dim': 128, 'temperature': 0.07, 'weight_decay': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "log_dir = './runs/simclr_vgg_150'\n",
    "\n",
    "with open(os.path.join(log_dir, 'config.yml')) as file:\n",
    "  config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VoxVGG(\n",
      "  (conv1): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv3): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv4): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv5): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv6): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv7): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv8): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv9): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv10): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (last_fc): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import Simple3DCNN, VoxVGG, VoxResNet\n",
    "\n",
    "if config['arch'] == 'simple':\n",
    "    model = Simple3DCNN(class_nums=3)\n",
    "elif config['arch'] == 'vgg':\n",
    "    model = VoxVGG(class_nums=3)\n",
    "elif config['arch'] == 'resnet':\n",
    "    model = VoxResNet(class_nums=3)\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./runs/simclr_vgg_150\\checkpoint_0150.pth.tar\n",
      "keys: ['backbone.conv1.weight', 'backbone.conv1.bias', 'backbone.conv2.weight', 'backbone.conv2.bias', 'backbone.conv3.weight', 'backbone.conv3.bias', 'backbone.conv4.weight', 'backbone.conv4.bias', 'backbone.conv5.weight', 'backbone.conv5.bias', 'backbone.conv6.weight', 'backbone.conv6.bias', 'backbone.conv7.weight', 'backbone.conv7.bias', 'backbone.conv8.weight', 'backbone.conv8.bias', 'backbone.conv9.weight', 'backbone.conv9.bias', 'backbone.conv10.weight', 'backbone.conv10.bias', 'backbone.fc.weight', 'backbone.fc.bias', 'backbone.bn.weight', 'backbone.bn.bias', 'backbone.bn.running_mean', 'backbone.bn.running_var', 'backbone.bn.num_batches_tracked', 'backbone.last_fc.0.weight', 'backbone.last_fc.0.bias', 'backbone.last_fc.2.weight', 'backbone.last_fc.2.bias']\n",
      "backbone.last_fc.0.weight\n",
      "backbone.last_fc.0.bias\n",
      "backbone.last_fc.2.weight\n",
      "backbone.last_fc.2.bias\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filename = 'checkpoint_{:04}.pth.tar'.format(config['epochs'])\n",
    "checkpoint_path = os.path.join(log_dir, checkpoint_filename)\n",
    "print(checkpoint_path)\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "state_dict = checkpoint['state_dict']\n",
    "print('keys:', list(state_dict.keys()))\n",
    "\n",
    "for k in list(state_dict.keys()):\n",
    "  if k.startswith('backbone.'):\n",
    "    if k.startswith('backbone') and not k.startswith('backbone.last_fc'):\n",
    "      # remove prefix\n",
    "      state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
    "    else:\n",
    "      print(k)\n",
    "  del state_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last_fc.weight', 'last_fc.bias']\n"
     ]
    }
   ],
   "source": [
    "log = model.load_state_dict(state_dict, strict=False)\n",
    "print(log.missing_keys)\n",
    "assert log.missing_keys == ['last_fc.weight', 'last_fc.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size: 980\n",
      "train_size: 686\n",
      "test_size: 294\n"
     ]
    }
   ],
   "source": [
    "if config['dataset_name'] == 'mri':\n",
    "    train_loader, test_loader = get_data_loaders(batch_size=config['batch_size'] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "# freeze all layers but the last fc\n",
    "for name, param in model.named_parameters():\n",
    "    if name not in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        print(name)\n",
    "\n",
    "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "assert len(parameters) == 2  # fc.weight, fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, train\n",
      "epoch:1, test\n",
      "Epoch 1\tTop1 Train accuracy 38.82890319824219\tTop1 Test accuracy: 39.47368621826172\tTop3 test acc: 100.0\n",
      "epoch:2, train\n",
      "epoch:2, test\n",
      "Epoch 2\tTop1 Train accuracy 47.21760940551758\tTop1 Test accuracy: 44.51754379272461\tTop3 test acc: 100.0\n",
      "epoch:3, train\n",
      "epoch:3, test\n",
      "Epoch 3\tTop1 Train accuracy 53.50913619995117\tTop1 Test accuracy: 48.355262756347656\tTop3 test acc: 100.0\n",
      "epoch:4, train\n",
      "epoch:4, test\n",
      "Epoch 4\tTop1 Train accuracy 55.481727600097656\tTop1 Test accuracy: 45.94298553466797\tTop3 test acc: 100.0\n",
      "epoch:5, train\n",
      "epoch:5, test\n",
      "Epoch 5\tTop1 Train accuracy 52.86545181274414\tTop1 Test accuracy: 45.28508758544922\tTop3 test acc: 100.0\n",
      "epoch:6, train\n",
      "epoch:6, test\n",
      "Epoch 6\tTop1 Train accuracy 55.793190002441406\tTop1 Test accuracy: 45.72368621826172\tTop3 test acc: 100.0\n",
      "epoch:7, train\n",
      "epoch:7, test\n",
      "Epoch 7\tTop1 Train accuracy 52.595516204833984\tTop1 Test accuracy: 48.135963439941406\tTop3 test acc: 100.0\n",
      "epoch:8, train\n",
      "epoch:8, test\n",
      "Epoch 8\tTop1 Train accuracy 55.50249099731445\tTop1 Test accuracy: 46.16228103637695\tTop3 test acc: 100.0\n",
      "epoch:9, train\n",
      "epoch:9, test\n",
      "Epoch 9\tTop1 Train accuracy 54.15282440185547\tTop1 Test accuracy: 48.02631759643555\tTop3 test acc: 100.0\n",
      "epoch:10, train\n",
      "epoch:10, test\n",
      "Epoch 10\tTop1 Train accuracy 55.793190002441406\tTop1 Test accuracy: 47.47806930541992\tTop3 test acc: 100.0\n",
      "epoch:11, train\n",
      "epoch:11, test\n",
      "Epoch 11\tTop1 Train accuracy 55.564781188964844\tTop1 Test accuracy: 48.68421173095703\tTop3 test acc: 100.0\n",
      "epoch:12, train\n",
      "epoch:12, test\n",
      "Epoch 12\tTop1 Train accuracy 53.820594787597656\tTop1 Test accuracy: 47.8070182800293\tTop3 test acc: 100.0\n",
      "epoch:13, train\n",
      "epoch:13, test\n",
      "Epoch 13\tTop1 Train accuracy 55.8554801940918\tTop1 Test accuracy: 47.25877380371094\tTop3 test acc: 100.0\n",
      "epoch:14, train\n",
      "epoch:14, test\n",
      "Epoch 14\tTop1 Train accuracy 55.52325439453125\tTop1 Test accuracy: 47.69736862182617\tTop3 test acc: 100.0\n",
      "epoch:15, train\n",
      "epoch:15, test\n",
      "Epoch 15\tTop1 Train accuracy 55.8139533996582\tTop1 Test accuracy: 46.92982482910156\tTop3 test acc: 100.0\n",
      "epoch:16, train\n",
      "epoch:16, test\n",
      "Epoch 16\tTop1 Train accuracy 56.58222579956055\tTop1 Test accuracy: 46.16228103637695\tTop3 test acc: 100.0\n",
      "epoch:17, train\n",
      "epoch:17, test\n",
      "Epoch 17\tTop1 Train accuracy 55.564781188964844\tTop1 Test accuracy: 47.3684196472168\tTop3 test acc: 100.0\n",
      "epoch:18, train\n",
      "epoch:18, test\n",
      "Epoch 18\tTop1 Train accuracy 55.4401969909668\tTop1 Test accuracy: 49.122806549072266\tTop3 test acc: 100.0\n",
      "epoch:19, train\n",
      "epoch:19, test\n",
      "Epoch 19\tTop1 Train accuracy 57.184383392333984\tTop1 Test accuracy: 48.79385757446289\tTop3 test acc: 100.0\n",
      "epoch:20, train\n",
      "epoch:20, test\n",
      "Epoch 20\tTop1 Train accuracy 54.69268798828125\tTop1 Test accuracy: 46.3815803527832\tTop3 test acc: 100.0\n",
      "epoch:21, train\n",
      "epoch:21, test\n",
      "Epoch 21\tTop1 Train accuracy 57.55813980102539\tTop1 Test accuracy: 45.83333206176758\tTop3 test acc: 100.0\n",
      "epoch:22, train\n",
      "epoch:22, test\n",
      "Epoch 22\tTop1 Train accuracy 56.58222579956055\tTop1 Test accuracy: 48.68421173095703\tTop3 test acc: 100.0\n",
      "epoch:23, train\n",
      "epoch:23, test\n",
      "Epoch 23\tTop1 Train accuracy 57.288204193115234\tTop1 Test accuracy: 48.79385757446289\tTop3 test acc: 100.0\n",
      "epoch:24, train\n",
      "epoch:24, test\n",
      "Epoch 24\tTop1 Train accuracy 56.14617919921875\tTop1 Test accuracy: 48.46491241455078\tTop3 test acc: 100.0\n",
      "epoch:25, train\n",
      "epoch:25, test\n",
      "Epoch 25\tTop1 Train accuracy 57.184383392333984\tTop1 Test accuracy: 50.438594818115234\tTop3 test acc: 100.0\n",
      "epoch:26, train\n",
      "epoch:26, test\n",
      "Epoch 26\tTop1 Train accuracy 57.45431900024414\tTop1 Test accuracy: 47.3684196472168\tTop3 test acc: 100.0\n",
      "epoch:27, train\n",
      "epoch:27, test\n",
      "Epoch 27\tTop1 Train accuracy 56.12541580200195\tTop1 Test accuracy: 48.68421173095703\tTop3 test acc: 100.0\n",
      "epoch:28, train\n",
      "epoch:28, test\n",
      "Epoch 28\tTop1 Train accuracy 58.118770599365234\tTop1 Test accuracy: 46.16228103637695\tTop3 test acc: 100.0\n",
      "epoch:29, train\n",
      "epoch:29, test\n",
      "Epoch 29\tTop1 Train accuracy 57.37126541137695\tTop1 Test accuracy: 49.561405181884766\tTop3 test acc: 100.0\n",
      "epoch:30, train\n",
      "epoch:30, test\n",
      "Epoch 30\tTop1 Train accuracy 56.97674560546875\tTop1 Test accuracy: 48.135963439941406\tTop3 test acc: 100.0\n",
      "epoch:31, train\n",
      "epoch:31, test\n",
      "Epoch 31\tTop1 Train accuracy 56.58222579956055\tTop1 Test accuracy: 48.79385757446289\tTop3 test acc: 100.0\n",
      "epoch:32, train\n",
      "epoch:32, test\n",
      "Epoch 32\tTop1 Train accuracy 57.641197204589844\tTop1 Test accuracy: 48.02631759643555\tTop3 test acc: 100.0\n",
      "epoch:33, train\n",
      "epoch:33, test\n",
      "Epoch 33\tTop1 Train accuracy 57.47507858276367\tTop1 Test accuracy: 48.46491241455078\tTop3 test acc: 100.0\n",
      "epoch:34, train\n",
      "epoch:34, test\n",
      "Epoch 34\tTop1 Train accuracy 56.706809997558594\tTop1 Test accuracy: 49.01315689086914\tTop3 test acc: 100.0\n",
      "epoch:35, train\n",
      "epoch:35, test\n",
      "Epoch 35\tTop1 Train accuracy 57.225914001464844\tTop1 Test accuracy: 48.2456169128418\tTop3 test acc: 100.0\n",
      "epoch:36, train\n",
      "epoch:36, test\n",
      "Epoch 36\tTop1 Train accuracy 56.14617919921875\tTop1 Test accuracy: 50.21929931640625\tTop3 test acc: 100.0\n",
      "epoch:37, train\n",
      "epoch:37, test\n",
      "Epoch 37\tTop1 Train accuracy 55.980064392089844\tTop1 Test accuracy: 47.25877380371094\tTop3 test acc: 100.0\n",
      "epoch:38, train\n",
      "epoch:38, test\n",
      "Epoch 38\tTop1 Train accuracy 56.6445198059082\tTop1 Test accuracy: 46.82017517089844\tTop3 test acc: 100.0\n",
      "epoch:39, train\n",
      "epoch:39, test\n",
      "Epoch 39\tTop1 Train accuracy 56.99750900268555\tTop1 Test accuracy: 48.68421173095703\tTop3 test acc: 100.0\n",
      "epoch:40, train\n",
      "epoch:40, test\n",
      "Epoch 40\tTop1 Train accuracy 57.03903579711914\tTop1 Test accuracy: 48.135963439941406\tTop3 test acc: 100.0\n",
      "epoch:41, train\n",
      "epoch:41, test\n",
      "Epoch 41\tTop1 Train accuracy 56.14617919921875\tTop1 Test accuracy: 47.58771896362305\tTop3 test acc: 100.0\n",
      "epoch:42, train\n",
      "epoch:42, test\n",
      "Epoch 42\tTop1 Train accuracy 55.64784240722656\tTop1 Test accuracy: 49.561405181884766\tTop3 test acc: 100.0\n",
      "epoch:43, train\n",
      "epoch:43, test\n",
      "Epoch 43\tTop1 Train accuracy 57.74501419067383\tTop1 Test accuracy: 47.8070182800293\tTop3 test acc: 100.0\n",
      "epoch:44, train\n",
      "epoch:44, test\n",
      "Epoch 44\tTop1 Train accuracy 56.6860466003418\tTop1 Test accuracy: 50.657894134521484\tTop3 test acc: 100.0\n",
      "epoch:45, train\n",
      "epoch:45, test\n",
      "Epoch 45\tTop1 Train accuracy 56.54069900512695\tTop1 Test accuracy: 47.8070182800293\tTop3 test acc: 100.0\n",
      "epoch:46, train\n",
      "epoch:46, test\n",
      "Epoch 46\tTop1 Train accuracy 57.86960220336914\tTop1 Test accuracy: 49.342105865478516\tTop3 test acc: 100.0\n",
      "epoch:47, train\n",
      "epoch:47, test\n",
      "Epoch 47\tTop1 Train accuracy 56.43687438964844\tTop1 Test accuracy: 50.328948974609375\tTop3 test acc: 100.0\n",
      "epoch:48, train\n",
      "epoch:48, test\n",
      "Epoch 48\tTop1 Train accuracy 57.89036178588867\tTop1 Test accuracy: 47.47806930541992\tTop3 test acc: 100.0\n",
      "epoch:49, train\n",
      "epoch:49, test\n",
      "Epoch 49\tTop1 Train accuracy 56.706809997558594\tTop1 Test accuracy: 49.45175552368164\tTop3 test acc: 100.0\n",
      "epoch:50, train\n",
      "epoch:50, test\n",
      "Epoch 50\tTop1 Train accuracy 56.208473205566406\tTop1 Test accuracy: 49.89035415649414\tTop3 test acc: 100.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    top1_train_accuracy = 0\n",
    "    print(f'epoch:{epoch + 1}, train')\n",
    "    for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
    "        top1_train_accuracy += top1[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    top1_train_accuracy /= counter + 1\n",
    "    top1_accuracy = 0\n",
    "    top3_accuracy = 0\n",
    "    print(f'epoch:{epoch + 1}, test')\n",
    "    for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(x_batch)\n",
    "\n",
    "        top1, top3 = accuracy(logits, y_batch, topk=(1, 3))\n",
    "        top1_accuracy += top1[0]\n",
    "        top3_accuracy += top3[0]\n",
    "\n",
    "    top1_accuracy /= counter + 1\n",
    "    top3_accuracy /= counter + 1\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop3 test acc: {top3_accuracy.item()}\"\n",
    "    )\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "    }\n",
    "    torch.save(state, os.path.join('checkpoint', 'checkpoint_eval.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simclr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
