{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(device=device(type='cuda'), batch_size=8, n_views=2, temperature=0.07, fp16_precision=False, arch='resnet', log_every_n_steps=100, learning_rate=3e-05, epochs=150, disable_cuda=False, dataset_dir='E:\\\\Data\\\\ADNI\\\\adni-fnirt-corrected', csv_path='E:\\\\Data\\\\ADNI\\\\pheno_ADNI_longitudinal_new.csv', dataset_name='mri', weight_decay=0.0001, out_dim=128)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.batch_size = 8\n",
    "args.n_views = 2\n",
    "args.temperature = 0.07\n",
    "args.fp16_precision = False\n",
    "args.arch = 'vgg'\n",
    "args.log_every_n_steps = 100\n",
    "args.learning_rate = 0.00003\n",
    "args.epochs = 150\n",
    "args.disable_cuda = not torch.cuda.is_available()\n",
    "args.dataset_dir = r\"E:\\Data\\ADNI\\adni-fnirt-corrected\"\n",
    "args.csv_path = r\"E:\\Data\\ADNI\\pheno_ADNI_longitudinal_new.csv\"\n",
    "args.dataset_name = 'mri'\n",
    "args.weight_decay = 1e-4\n",
    "args.out_dim = 128\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSimCLRException(Exception):\n",
    "    \"\"\"Base exception\"\"\"\n",
    "\n",
    "\n",
    "class InvalidBackboneError(BaseSimCLRException):\n",
    "    \"\"\"Raised when the choice of backbone Convnet is invalid.\"\"\"\n",
    "\n",
    "\n",
    "class InvalidDatasetSelection(BaseSimCLRException):\n",
    "    \"\"\"Raised when the choice of dataset is invalid.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "\n",
    "class ContrastiveLearningViewGenerator(object):\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform, n_views=2):\n",
    "        self.base_transform = base_transform\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transform(x) for i in range(self.n_views)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "from torchvision import transforms, datasets\n",
    "from mri_dataset import ADNIDataset\n",
    "from monai.transforms import *\n",
    "from data_augmentation import MRIAugmentation\n",
    "\n",
    "class ContrastiveLearningDataset:\n",
    "    def __init__(self, root_folder, csv_path):\n",
    "        self.root_folder = root_folder\n",
    "        self.csv_path = csv_path\n",
    "\n",
    "    @staticmethod\n",
    "    def get_simclr_pipeline_transform(size, s=1):\n",
    "        \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "        # data_transforms = Compose([\n",
    "        #     RandRotate90(prob=0.5, spatial_axes=[1, 2]),\n",
    "        #     RandRotate90(prob=0.5, spatial_axes=[0, 1]),\n",
    "        #     RandRotate90(prob=0.5, spatial_axes=[0, 2]),\n",
    "        #     RandFlip(prob=0.5, spatial_axis=0),\n",
    "        #     RandFlip(prob=0.5, spatial_axis=1),\n",
    "        #     RandFlip(prob=0.5, spatial_axis=2),\n",
    "            \n",
    "        #     RandAdjustContrast(prob=1, gamma=(0.5, 1.5)),\n",
    "        #     RandGaussianNoise(prob=1),\n",
    "        #     # RandAffine(prob=args['prob'], translate_range=10, scale_range=(0.9, 1.1), rotate_range=45),\n",
    "            \n",
    "        #     Resize(spatial_size=[100, 100, 100]),\n",
    "        #     NormalizeIntensity(channel_wise=True),\n",
    "        # ])\n",
    "        data_transforms = MRIAugmentation.get_augmentation_transforms()\n",
    "    \n",
    "        \n",
    "        return data_transforms\n",
    "\n",
    "    def get_dataset(self, name, n_views):\n",
    "        valid_datasets = {}\n",
    "\n",
    "        valid_datasets['mri'] = lambda: ADNIDataset(data_dir=self.root_folder, csv_path=self.csv_path, transform=ContrastiveLearningViewGenerator(self.get_simclr_pipeline_transform(100), n_views))\n",
    "        try:\n",
    "            dataset_fn = valid_datasets[name]\n",
    "        except KeyError:\n",
    "            raise InvalidDatasetSelection()\n",
    "        else:\n",
    "            return dataset_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ContrastiveLearningDataset(args.dataset_dir, args.csv_path)\n",
    "train_dataset = dataset.get_dataset(args.dataset_name, args.n_views)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def save_config_file(model_checkpoints_folder, args):\n",
    "    if not os.path.exists(model_checkpoints_folder):\n",
    "        os.makedirs(model_checkpoints_folder)\n",
    "    with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n",
    "        args_dict = vars(args)\n",
    "        args_dict['device'] = args_dict['device'].type\n",
    "        yaml.dump(args_dict, outfile, default_flow_style=False)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "\n",
    "class SimCLR(object):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.args = kwargs['args']\n",
    "        self.model = kwargs['model'].to(self.args.device)\n",
    "        self.optimizer = kwargs['optimizer']\n",
    "        self.scheduler = kwargs['scheduler']\n",
    "        self.writer = SummaryWriter()\n",
    "        logging.basicConfig(filename=os.path.join(self.writer.log_dir, 'training.log'), level=logging.DEBUG)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n",
    "\n",
    "    def info_nce_loss(self, features):\n",
    "\n",
    "        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.args.device)\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        # assert similarity_matrix.shape == (\n",
    "        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # discard the main diagonal from both: labels and similarities matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # select and combine multiple positives\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "        # select only the negatives the negatives\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)\n",
    "\n",
    "        logits = logits / self.args.temperature\n",
    "        return logits, labels\n",
    "\n",
    "    def train(self, train_loader):\n",
    "\n",
    "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
    "\n",
    "        # save config file\n",
    "        save_config_file(self.writer.log_dir, self.args)\n",
    "\n",
    "        n_iter = 0\n",
    "        logging.info(f\"Start SimCLR training for {self.args.epochs} epochs.\")\n",
    "        logging.info(f\"Training with gpu: {not self.args.disable_cuda}.\")\n",
    "\n",
    "        for epoch_counter in range(1, self.args.epochs + 1):\n",
    "            for images, _ in tqdm(train_loader):\n",
    "                images = torch.cat(images, dim=0)\n",
    "\n",
    "                images = images.to(self.args.device)\n",
    "\n",
    "                with autocast(enabled=self.args.fp16_precision):\n",
    "                    features = self.model(images)\n",
    "                    logits, labels = self.info_nce_loss(features)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "                if n_iter % self.args.log_every_n_steps == 0:\n",
    "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "                    self.writer.add_scalar('loss', loss, global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top1', top1[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top5', top5[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('learning_rate', self.scheduler.get_last_lr()[0], global_step=n_iter)\n",
    "\n",
    "                n_iter += 1\n",
    "\n",
    "            # warmup for the first 10 epochs\n",
    "            if epoch_counter > 10:\n",
    "                self.scheduler.step()\n",
    "            logging.debug(f\"Epoch: {epoch_counter + 1}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "            \n",
    "            if epoch_counter % 5 == 0:\n",
    "            \n",
    "                checkpoint_name = 'checkpoint_{:04d}.pth'.format(self.args.epochs)\n",
    "                save_checkpoint({\n",
    "                    'epoch': self.args.epochs,\n",
    "                    'arch': self.args.arch,\n",
    "                    'model': self.model.state_dict(),\n",
    "                    'optimizer': self.optimizer.state_dict(),\n",
    "                }, is_best=False, filename=os.path.join(self.writer.log_dir, checkpoint_name))\n",
    "\n",
    "        logging.info(\"Training has finished.\")\n",
    "        # save model checkpoints\n",
    "        checkpoint_name = 'checkpoint_{:04d}.pth'.format(self.args.epochs)\n",
    "        save_checkpoint({\n",
    "            'epoch': self.args.epochs,\n",
    "            'arch': self.args.arch,\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }, is_best=False, filename=os.path.join(self.writer.log_dir, checkpoint_name))\n",
    "        logging.info(f\"Model checkpoint and metadata has been saved at {self.writer.log_dir}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VoxResNet_SimCLR(\n",
      "  (backbone): VoxResNet(\n",
      "    (conv1a): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (bn1a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1b): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (bn1b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1c): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
      "    (voxres2): Sequential(\n",
      "      (0): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "      (3): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    )\n",
      "    (voxres3): Sequential(\n",
      "      (0): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "      (3): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    )\n",
      "    (conv4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "    (voxres5): Sequential(\n",
      "      (0): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "      (3): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    )\n",
      "    (voxres6): Sequential(\n",
      "      (0): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "      (3): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    )\n",
      "    (last_fc): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import Simple3DCNN_SimCLR, VoxVGG_SimCLR, VoxResNet_SimCLR\n",
    "\n",
    "if args.arch == 'simple':\n",
    "    model = Simple3DCNN_SimCLR(out_dim=args.out_dim)\n",
    "elif args.arch == 'vgg':\n",
    "    model = VoxVGG_SimCLR(out_dim=args.out_dim)\n",
    "elif args.arch == 'resnet':\n",
    "    model = VoxResNet_SimCLR(out_dim=args.out_dim)\n",
    "else:\n",
    "    raise InvalidBackboneError(\"Invalid backbone architecture.\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 63/495 [10:09:02<69:36:14, 580.03s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), eta_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, last_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m simclr \u001b[38;5;241m=\u001b[39m SimCLR(model\u001b[38;5;241m=\u001b[39mmodel, optimizer\u001b[38;5;241m=\u001b[39moptimizer, scheduler\u001b[38;5;241m=\u001b[39mscheduler, args\u001b[38;5;241m=\u001b[39margs)\n\u001b[1;32m----> 6\u001b[0m \u001b[43msimclr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 69\u001b[0m, in \u001b[0;36mSimCLR.train\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[0;32m     67\u001b[0m     images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(images, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mfp16_precision):\n\u001b[0;32m     72\u001b[0m         features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(images)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\mri\\Lib\\site-packages\\monai\\data\\meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\mri\\Lib\\site-packages\\torch\\_tensor.py:1418\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1418\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0, last_epoch=-1)\n",
    "\n",
    "simclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "simclr.train(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simclr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
