{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from medcam import medcam\n",
    "from monai import transforms\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from model import *\n",
    "from matplotlib import colormaps\n",
    "from scipy.ndimage import zoom\n",
    "from util import Util\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VoxVGG(3).to(device)\n",
    "# model = VoxResNet().to(device)\n",
    "\n",
    "# checkpoint_path = r\"C:\\Users\\17993\\Downloads\\best_epoch17.pth\"\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "\n",
    "# # 加载模型权重\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "# # 获取保存的accuracy, loss和epoch\n",
    "# accuracy = checkpoint['accuracy']\n",
    "# validation_loss = checkpoint['loss']\n",
    "# epoch = checkpoint['epoch']\n",
    "# print(f\"Model loaded successfully with accuracy: {100.*accuracy:.2f}%, loss: {validation_loss:.6f}, at epoch: {epoch}\")\n",
    "\n",
    "model = medcam.inject(model, output_dir='attention_maps', backend='gcam', save_maps=False, return_attention=True, layer='conv10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(spatial_size=[100, 100, 100]),\n",
    "    transforms.NormalizeIntensity(nonzero=True, channel_wise=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\"C:\\Custom\\DataSet\\ADNI_预处理后\\Image\\brain_adni_0021_I196077_fsld.nii.gz\"\n",
    "nii_img = nib.load(img_path).get_fdata()\n",
    "nii_img = nii_img.astype(np.float32)\n",
    "original_img = nii_img\n",
    "nii_img = torch.from_numpy(nii_img)\n",
    "nii_img = nii_img.unsqueeze(0)\n",
    "nii_img = transform(nii_img)\n",
    "nii_img = nii_img.unsqueeze(0)\n",
    "nii_img = nii_img.as_tensor()\n",
    "print(nii_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img[0][0][40][45][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img[40][45][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 进行预测\n",
    "    outputs, attention_map = model(nii_img)\n",
    "    # 输出处理，获取预测结果\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    attention_map = attention_map.detach().cpu().numpy()\n",
    "attention_map = np.squeeze(attention_map)\n",
    "print('predicted:', predicted)\n",
    "print('attention_map shape:', attention_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imsave('./attention_maps/test.jpg', attention_map[40], cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_idx = 50\n",
    "print(original_img[:,:,slice_idx].shape)\n",
    "plt.imshow(np.flipud(original_img[:,:,slice_idx].T), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in range(110):\n",
    "    for j in range(110):\n",
    "        for k in range(110):\n",
    "            if attention_map[i][j][k] == 0:\n",
    "                cnt += 1\n",
    "            else:\n",
    "                print(\"test\")\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.flipud(attention_map[:,:,45].T), cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attention_map.shape)\n",
    "print(original_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 计算新旧尺寸的缩放比例\n",
    "zoom_factors = np.array((91, 109, 91)) / np.array(attention_map.shape)\n",
    "# 使用 zoom 函数调整数组大小\n",
    "attention_map = zoom(attention_map, zoom_factors, order=0)  # order=3 代表三次样条插值\n",
    "print(attention_map.shape)\n",
    "print(original_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 归一化\n",
    "attention_map = Util.normalize_image_0_to_1(attention_map)\n",
    "original_img = Util.normalize_image_0_to_1(original_img)\n",
    "# 获取热力图颜色映射\n",
    "\n",
    "cmap = colormaps['jet']  # 你可以选择其他颜色映射\n",
    "attention_map_colored = cmap(attention_map)\n",
    "plt.imsave('./attention_maps/test.jpg', attention_map[40], cmap=\"jet\")\n",
    "# 将颜色映射的alpha值设置为热力图的正规化值，以创建透明度效果\n",
    "# 这允许原始图像通过热力图显示\n",
    "attention_map_colored[..., -1] = attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个图像来显示结果\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(original_img[45], vmin=0, vmax=1, cmap=\"gray\")\n",
    "ax.imshow(attention_map_colored[45], alpha=0.7, vmin=0, vmax=1)  # 调整alpha以改变叠加层的透明度\n",
    "plt.axis('off')  # 关闭坐标轴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(image:np.ndarray, attention_map:np.ndarray, alpha=0.7):\n",
    "    # 缩放热力图适应原图\n",
    "    zoom_factors = np.array((image.shape[0], image.shape[1], image.shape[2])) / np.array(attention_map.shape)\n",
    "    attention_map = zoom(attention_map, zoom_factors, order=3, mode=\"reflect\")  # order=3 代表三次样条插值\n",
    "    \n",
    "    # 归一化\n",
    "    image = Util.normalize_image_0_to_1(image)\n",
    "    attention_map = Util.normalize_image_0_to_1(attention_map)\n",
    "    \n",
    "    # 处理热力图\n",
    "    cmap = colormaps['jet']  # 你可以选择其他颜色映射\n",
    "    attention_map_colored = cmap(attention_map)\n",
    "    attention_map_colored[..., -1] = attention_map\n",
    "    attention_map = attention_map_colored\n",
    "    \n",
    "    # 将灰度图转换为 RGB\n",
    "    image_rgb = np.stack([image] * 3, axis=-1)\n",
    "    # 提取 RGBA 热力图的颜色和 alpha 通道\n",
    "    color_layer = attention_map[..., :3]\n",
    "    alpha_layer = attention_map[..., 3:]\n",
    "    # 使用热力图的 alpha 通道来混合原图和热力图的颜色\n",
    "    overlap_image = (alpha * alpha_layer) * color_layer + (1 - (alpha_layer * alpha)) * image_rgb\n",
    "    return overlap_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_image = overlap(original_img, attention_map, alpha=0.7)\n",
    "print(overlap_image.shape)\n",
    "plt.imshow(overlap_image[45], vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(original_img[45], alpha=1, vmin=0, vmax=1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设 original_img 和 attention_map_colored 已经定义\n",
    "\n",
    "# 将灰度图转换为 RGB\n",
    "original_img_rgb = np.stack([original_img]*3, axis=-1)\n",
    "\n",
    "# 计算叠加图像\n",
    "# 提取 RGBA 热力图的颜色和 alpha 通道\n",
    "color_layer = attention_map_colored[..., :3]\n",
    "alpha_layer = attention_map_colored[..., 3:]\n",
    "\n",
    "# 使用热力图的 alpha 通道来混合原图和热力图的颜色\n",
    "combined_img = 0 * alpha_layer * color_layer + (1 - alpha_layer * 0) * original_img_rgb\n",
    "\n",
    "# combined_img 现在是叠加了热力图的 RGB 图像\n",
    "plt.imshow(combined_img[45], vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 指定要清空的文件夹路径\n",
    "folder_path = r'C:\\Users\\17993\\Desktop\\test\\vector'\n",
    "\n",
    "# 遍历文件夹中的所有文件和子文件夹\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    try:\n",
    "        # 如果是文件，则删除\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.remove(file_path)\n",
    "        # 如果是目录，则删除目录及其所有内容（可选）\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to delete {file_path}. Reason: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
